{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'sc' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m-----------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0mTraceback (most recent call last)",
      "\u001b[1;32m<ipython-input-7-8d3513b7698b>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0msc\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstop\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'sc' is not defined"
     ]
    }
   ],
   "source": [
    "sc.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'sys' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m-----------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0mTraceback (most recent call last)",
      "\u001b[1;32m<ipython-input-5-c860b97acecd>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Python Version: \"\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0msys\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mversion\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"\\nPySpark version: \"\u001b[0m\u001b[1;33m+\u001b[0m \u001b[0msc\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mversion\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'sys' is not defined"
     ]
    }
   ],
   "source": [
    "print(\"Python Version: \" + sys.version, \"\\nPySpark version: \"+ sc.version)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m-----------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0mTraceback (most recent call last)",
      "\u001b[1;32m<ipython-input-8-925860dbc138>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[1;31m#os.environ['PYSPARK_DRIVER_PYTHON'] = sys.executable\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mpyspark\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mSparkContext\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 10\u001b[1;33m \u001b[0msc\u001b[0m\u001b[1;33m=\u001b[0m \u001b[0mSparkContext\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"local[*]\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"wordcount\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pyspark\\context.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, master, appName, sparkHome, pyFiles, environment, batchSize, serializer, conf, gateway, jsc, profiler_cls)\u001b[0m\n\u001b[0;32m    131\u001b[0m                     \" note this option will be removed in Spark 3.0\")\n\u001b[0;32m    132\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 133\u001b[1;33m         \u001b[0mSparkContext\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_ensure_initialized\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgateway\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mgateway\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mconf\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mconf\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    134\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    135\u001b[0m             self._do_init(master, appName, sparkHome, pyFiles, environment, batchSize, serializer,\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pyspark\\context.py\u001b[0m in \u001b[0;36m_ensure_initialized\u001b[1;34m(cls, instance, gateway, conf)\u001b[0m\n\u001b[0;32m    314\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mSparkContext\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    315\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mSparkContext\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_gateway\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 316\u001b[1;33m                 \u001b[0mSparkContext\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_gateway\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgateway\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mlaunch_gateway\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mconf\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    317\u001b[0m                 \u001b[0mSparkContext\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_jvm\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mSparkContext\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_gateway\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjvm\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    318\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pyspark\\java_gateway.py\u001b[0m in \u001b[0;36mlaunch_gateway\u001b[1;34m(conf)\u001b[0m\n\u001b[0;32m     44\u001b[0m     \u001b[1;33m:\u001b[0m\u001b[1;32mreturn\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0ma\u001b[0m \u001b[0mJVM\u001b[0m \u001b[0mgateway\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     45\u001b[0m     \"\"\"\n\u001b[1;32m---> 46\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0m_launch_gateway\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mconf\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     47\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     48\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pyspark\\java_gateway.py\u001b[0m in \u001b[0;36m_launch_gateway\u001b[1;34m(conf, insecure)\u001b[0m\n\u001b[0;32m    103\u001b[0m             \u001b[1;31m# Wait for the file to appear, or for the process to exit, whichever happens first.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    104\u001b[0m             \u001b[1;32mwhile\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mproc\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpoll\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mand\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0misfile\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mconn_info_file\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 105\u001b[1;33m                 \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msleep\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0.1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    106\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    107\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0misfile\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mconn_info_file\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "import findspark\n",
    "findspark.init()\n",
    "#findspark.find()\n",
    "from pyspark import SparkContext\n",
    "#os.environ['PYSPARK_PYTHON'] = sys.executable\n",
    "#os.environ['PYSPARK_DRIVER_PYTHON'] = sys.executable\n",
    "from pyspark import SparkContext\n",
    "sc= SparkContext(\"local[*]\", \"wordcount\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "input1= sc.textFile(r\"C:\\Users\\LENOVO\\Desktop\\search_data.txt.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "words= input1.flatMap(lambda x: x.split(\" \"))\n",
    "word_count= words.map(lambda x: (x,1))\n",
    "final_count= word_count.map(lambda x,y: x+y)\n",
    "result= final_count.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in result:\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Q1 Highest Purchase\n",
    "\n",
    "from pyspark import SparkContext\n",
    "sc= SparkContext(\"local[*]\")\n",
    "rdd1= sc.textFile(\"C:/Users/LENOVO/Desktop/TrendyTech/w9_scala_spark/search_data-201008-180523.txt\")\n",
    "rdd2= rdd1.flatMap(lambda x: (x.split(\" \")[0], float(x.split(\",\")[2])))\n",
    "rdd3= rdd2.reduceByKey(lambda x,y: x+y)\n",
    "rdd4= rdd3.sortBy(lambda x: x[1], Flase)\n",
    "result= rdd4.collect()\n",
    "\n",
    "for i in result:\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Q2 Movie Rating Question\n",
    "\n",
    "from pyspark import SparkContext\n",
    "sc= SparkContext(\"local[*]\")\n",
    "movie= sc.textFile(\"C:\\Users\\LENOVO\\Desktop\\TrendyTech\\w9_scala_spark\\moviedata-201008-180523.data\")\n",
    "ratings= movie.flatMap(lambda x: (x.split(\"\\t\")[2], 1)\n",
    "result= ratings.reduceByKey(lambda x,y: x+y).collect()\n",
    "\n",
    "for i in result:\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Q3 Friends by Age\n",
    "\n",
    "def parseline(line):\n",
    "    fields= line.split(\",\")\n",
    "    age= int(fields[2])\n",
    "    numFriends= int(fields[3])\n",
    "    return(age,numFriends)\n",
    "\n",
    "from pyspark import SparkContext\n",
    "sc= SparkContext(\"local[*]\")\n",
    "data= sc.textFile(\"C:\\Users\\LENOVO\\Desktop\\TrendyTech\\w9_scala_spark\\friendsdata-201008-180523.csv\")\n",
    "rdd= data.map(parseline)\n",
    "total_age= rdd.mapValues(lambda x: (x,1)).reduceByKey(lambda x,y: (x[0]+y[0], x[1]+y[1]))\n",
    "avg_age= total_age.mapValue(lambda x: x[0]/x[1])\n",
    "result= avg_age.collect()\n",
    "\n",
    "for i in result:\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark import SparkContext\n",
    "sc= SparkContext(\"local[*]\")\n",
    "print(sc.version)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark 2.4.5\n",
    "scala 2.12.x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "User Variable\n",
    "\n",
    "%SCALA_HOME%\n",
    "C:\\Program Files\\scala-2.11.5\n",
    "%PATH%;%SCALA_HOME%\\bin\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sc.version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "C:\\Users\\LENOVO\\Anaconda3\\lib\\site-packages\\pyspark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "https://spark.apache.org/docs/2.4.5/#:~:text=Spark%20runs%20on%20Java%208,a%20compatible%20Scala%20version%20(2.12.\n",
    "\n",
    "Spark runs on Java 8, Python 2.7+/3.4+ and R 3.1+. For the Scala API, Spark 2.4.5 uses Scala 2.12. \n",
    "You will need to use a compatible Scala version (2.12.x)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-2-1ac0629d6f98>, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"<ipython-input-2-1ac0629d6f98>\"\u001b[1;36m, line \u001b[1;32m1\u001b[0m\n\u001b[1;33m    Latest we have\u001b[0m\n\u001b[1;37m            ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "Latest we have\n",
    "\n",
    "java version \"1.8.0_341\"\n",
    "Spark version- 2.4.5\n",
    "Scala code runner version 2.12.8\n",
    "sbt version in this project: 1.6.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C:\\\\Users\\\\LENOVO\\\\Anaconda3\\\\lib\\\\site-packages\\\\pyspark'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import findspark\n",
    "findspark.init()\n",
    "findspark.find()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-1-64f1d6ddcadd>, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"<ipython-input-1-64f1d6ddcadd>\"\u001b[1;36m, line \u001b[1;32m1\u001b[0m\n\u001b[1;33m    https://www.tutorialspoint.com/apache_spark/apache_spark_installation.htm\u001b[0m\n\u001b[1;37m           ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "https://www.tutorialspoint.com/apache_spark/apache_spark_installation.htm\n",
    "https://stackoverflow.com/questions/25481325/how-to-set-up-spark-on-windows\n",
    "https://spark.apache.org/docs/latest/\n",
    "https://phoenixnap.com/kb/install-spark-on-windows-10\n",
    "https://spark.apache.org/docs/2.4.5/#:~:text=Spark%20runs%20on%20Java%208,a%20compatible%20Scala%20version%20(2.12.\n",
    "https://datashark.academy/installing-spark-scala-sbt-s3-on-windows-machine/\n",
    "https://www.jetbrains.com/help/idea/sbt.html\n",
    "https://help.zend.com/zendstudio/current/content/working_with_eclipse_color_theme.htm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'Tasks'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m----------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0mTraceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-1a5ebf022321>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mdatetime\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mdatetime\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mTasks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreporting\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmarkettrack_generic_helpers\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mrender\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlocal_time\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      7\u001b[0m from Services.productdocumentsindexservice import (\n\u001b[0;32m      8\u001b[0m     \u001b[0mProductDocumentsIndexingCollection\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mPdi\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'Tasks'"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "EMTCS-26781- Custom report for CVS Pharma.\n",
    "\"\"\"\n",
    "\n",
    "from datetime import datetime\n",
    "from Tasks.reporting.markettrack_generic_helpers import render, local_time\n",
    "from Services.productdocumentsindexservice import (\n",
    "    ProductDocumentsIndexingCollection as Pdi,\n",
    ")\n",
    "\n",
    "CVS = 555616\n",
    "GSHOPPING = 360315\n",
    "TARGET = 10046\n",
    "WALGREENS = 10037\n",
    "AMAZON = 11\n",
    "RITEAID = 36082\n",
    "TARGET_MP = 36000525\n",
    "WALMART = 210\n",
    "AMAZON_MP = 110\n",
    "SEPHORA = 360067\n",
    "ULTA = 360125\n",
    "WALMART_MP = 2100\n",
    "CVS_ID = [CVS]\n",
    "GSHOPPING_ID = [GSHOPPING]\n",
    "TARGET_ID = [TARGET]\n",
    "WALGREENS_ID = [WALGREENS]\n",
    "AMAZON_ID = [AMAZON]\n",
    "RITEAID_ID = [RITEAID]\n",
    "TARGET_MP_ID = [TARGET_MP]\n",
    "WALMART_ID = [WALMART]\n",
    "AMAZON_MP_ID = [AMAZON_MP]\n",
    "SEPHORA_ID = [SEPHORA]\n",
    "ULTA_ID = [ULTA]\n",
    "WALMART_MP_ID = [WALMART_MP]\n",
    "\n",
    "\n",
    "def _store_formatter(_, doc):\n",
    "    \"\"\" Formatter for column WEBSITE NAME \"\"\"\n",
    "    if doc[Pdi.store_id] in CVS_ID:\n",
    "        return \"CVS.COM\"\n",
    "    elif doc[Pdi.store_id] in GSHOPPING_ID:\n",
    "        return \"GOOGLESHOPPING.COM\"\n",
    "    elif doc[Pdi.store_id] in TARGET_ID:\n",
    "        return \"TARGET.COM\"\n",
    "    elif doc[Pdi.store_id] in WALGREENS_ID:\n",
    "        return \"WALGREENS.COM\"\n",
    "    elif doc[Pdi.store_id] in AMAZON_ID:\n",
    "        return \"AMAZON.COM\"\n",
    "    elif doc[Pdi.store_id] in RITEAID_ID:\n",
    "        return \"RITEAID.COM\"\n",
    "    elif doc[Pdi.store_id] in TARGET_MP_ID:\n",
    "        return \"TARGET.COM\"\n",
    "    elif doc[Pdi.store_id] in WALMART_ID:\n",
    "        return \"WALMART.COM\"\n",
    "    elif doc[Pdi.store_id] in AMAZON_MP_ID:\n",
    "        return \"AMAZON.COM\"\n",
    "    elif doc[Pdi.store_id] in SEPHORA_ID:\n",
    "        return \"SEPHORA.COM\"\n",
    "    elif doc[Pdi.store_id] in ULTA_ID:\n",
    "        return \"ULTA.COM\"\n",
    "    elif doc[Pdi.store_id] in WALMART_MP_ID:\n",
    "        return \"WALMART.COM\"\n",
    "\n",
    "\n",
    "def create_daily_report(customer_context, limit):\n",
    "    \"\"\" Return report_spec for report generation. \"\"\"\n",
    "    limit = limit if limit else 0\n",
    "    report_spec = {\n",
    "        \"render\": render,\n",
    "        \"limit\": limit,\n",
    "        \"columns\": [\n",
    "            {\"entity\": \"crawl_date\", \"display_name\": \"Crawl Date\"},\n",
    "            {\"entity\": \"sku\", \"display_name\": \"COMP ID\"},\n",
    "            {\n",
    "                \"metadata\": {\"type\": \"string\"},\n",
    "                \"entity\": \"store\",\n",
    "                \"display_name\": \"WEBSITE NAME\",\n",
    "                \"data\": _store_formatter,\n",
    "                \"custom\": True,\n",
    "                \"fields\": [Pdi.store_id],\n",
    "            },\n",
    "            \"categories.0\",\n",
    "            {\"entity\": \"your.sku\", \"display_name\": \"CVS SKU\"},\n",
    "            {   \n",
    "                \"metadata\": {\"type\": \"string\"},\n",
    "                \"entity\": \"a\",\n",
    "                \"data\": lambda a, b: \"\",\n",
    "                \"custom\": True,\n",
    "                \"fields\": [],\n",
    "                \"display_name\": \"CVS PRIMARY SKU\",\n",
    "            },\n",
    "            {\"entity\": \"your.title\", \"display_name\": \"CVS.COM ITEM DESCRIPTION\"},\n",
    "            \"brand\",\n",
    "            {\"entity\": \"pack_size_value\", \"display_name\": \"PACK SIZE\"},\n",
    "            {\"entity\": \"pack_size_units\", \"display_name\": \"UNIT OF MEASURE\"},\n",
    "            {\"entity\": \"upc\", \"display_name\": \"UPC\"},\n",
    "            {\"entity\": \"price\", \"display_name\": \"Current Price\"},\n",
    "            {\"entity\": \"regular_price\", \"display_name\": \"Promo Price\"},\n",
    "        ],\n",
    "        \"filters\": [\n",
    "            [\n",
    "                \"and\",\n",
    "                [\n",
    "                    [\"crawl_date\", \">=\", {\"anchor\": \"today()\", \"days\": -1}],\n",
    "                    [\"your.sku\", \"!=\", None],\n",
    "                    [\"store_id\", \"!=\", customer_context.customer_id],\n",
    "                ],\n",
    "            ]\n",
    "        ],\n",
    "        \"model\": \"product_documents_reporting\",\n",
    "        \"datasource\": \"mongodb\",\n",
    "        \"selected_store\": customer_context.customer_id,\n",
    "    }\n",
    "    return report_spec\n",
    "\n",
    "\n",
    "def create_filename(customer_context, frequency, list_name):\n",
    "    \"\"\" Return filename for report generation. \"\"\"\n",
    "    return \"Numerator_to_{0}_{1}.csv\".format(\n",
    "        customer_context.customer_name,\n",
    "        local_time(customer_context, datetime.utcnow()).strftime(\"%Y%m%d%H\"),\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-2-01ec4e7791ca>, line 59)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"<ipython-input-2-01ec4e7791ca>\"\u001b[1;36m, line \u001b[1;32m59\u001b[0m\n\u001b[1;33m    {\"entity\": \"image\", \"display_name\": \"Product Image URL\"}\u001b[0m\n\u001b[1;37m    ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "EMTCS-27116.\n",
    "\n",
    "Weekly report for customernetretailersorgid587.\n",
    "\"\"\"\n",
    "\n",
    "from datetime import datetime\n",
    "\n",
    "from Services.productdocumentsindexservice import (\n",
    "    ProductDocumentsIndexingCollection as Pdi,\n",
    ")\n",
    "from Tasks.reporting.markettrack_generic_helpers import local_time\n",
    "\n",
    "\n",
    "def _get_prev_crawl_date(customer_context):\n",
    "    def _ret(_, doc):\n",
    "        prev_date = doc.get(Pdi.previous_price, {}).get(\"crawl_date\") or \"\"\n",
    "        if prev_date:\n",
    "            return local_time(customer_context, prev_date).strftime(\"%m/%d/%Y %H:%M\")\n",
    "        else:\n",
    "            return \"\"\n",
    "\n",
    "    return _ret\n",
    "\n",
    "\n",
    "def create_daily_report(customer_context, limit):\n",
    "    \"\"\"Return report_spec for report generation.\"\"\"\n",
    "    limit = limit if limit else 0\n",
    "\n",
    "    report_spec = {\n",
    "        \"limit\": limit,\n",
    "        \"model\": \"product_documents_reporting\",\n",
    "        \"datasource\": \"mongodb\",\n",
    "        \"selected_store\": customer_context.customer_id,\n",
    "        \"filters\": [\n",
    "            [\n",
    "                \"and\",\n",
    "                [\n",
    "                    [\"your.sku\", \"!=\", None],\n",
    "                    [\"crawl_date\", \">=\", {\"anchor\": \"today()\", \"days\": -7}],\n",
    "                    [\"crawl_date\", \"<\", {\"anchor\": \"today()\", \"days\": 1}],\n",
    "                ],\n",
    "            ]\n",
    "        ],\n",
    "        \"columns\": [\n",
    "            {\"entity\": \"your.custom_fields.plaid\", \"display_name\": \"PLAID\"},\n",
    "            {\"entity\": \"your.custom_fields.itemwebcode\", \"display_name\": \"ItemWebCode\"},\n",
    "            {\"entity\": \"your.title\", \"display_name\": \"Title\"},\n",
    "            {\"entity\": \"your.sku\", \"display_name\": \"SKU\"},\n",
    "            {\"entity\": \"categories.0\", \"display_name\": \"Category_Main\"},\n",
    "            {\"entity\": \"categories.1\", \"display_name\": \"Category_Sub1\"},\n",
    "            {\"entity\": \"your.upc\", \"display_name\": \"UPC\"},\n",
    "            {\"entity\": \"your.model\", \"display_name\": \"Model Number\"},\n",
    "            {\"entity\": \"map.map_price\", \"display_name\": \"MAP Price\"},\n",
    "            {\"entity\": \"your.pack_size_value\", \"display_name\": \"Pack Size\"},\n",
    "            {\"entity\": \"brand\", \"display_name\": \"Brand Name\"},\n",
    "            {\"entity\": \"your.custom_fields.status\", \"display_name\": \"Status\"},\n",
    "            {\"entity\": \"url\", \"display_name\": \"Product Page URL\"}\n",
    "            {\"entity\": \"image\", \"display_name\": \"Product Image URL\"}\n",
    "        ],\n",
    "    }\n",
    "    return report_spec\n",
    "\n",
    "\n",
    "def create_filename(customer_context, frequency, list_name):\n",
    "    \"\"\"Return filename for report generation.\"\"\"\n",
    "    return \"Numerator_to_Netretailers_{0}.csv\".format(\n",
    "        local_time(customer_context, datetime.utcnow()).strftime(\"%Y%m%d%H\")\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-3-79ea1b6fbc5f>, line 14)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"<ipython-input-3-79ea1b6fbc5f>\"\u001b[1;36m, line \u001b[1;32m14\u001b[0m\n\u001b[1;33m    },\u001b[0m\n\u001b[1;37m     ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    " \"customernetretailersorgid587\": {\n",
    "        \"weekly\": {\n",
    "            \"report_spec_generator\": \"netretailers_weekly_report\",\n",
    "            \"frequency\": 1,\n",
    "            \"report_list\": {\n",
    "                \"type\": ListsService.DOWNLOAD_REPORT_LIST_TYPE,\n",
    "                \"name\": ALL_PRODUCTS_LIST_NAME,\n",
    "            },\n",
    "            \"send_to_and_notify\": (\n",
    "                (\"production-s3\", \"mongodb\"),\n",
    "                (\"sftp-root\", \"stdout\"),\n",
    "            ),\n",
    "        },\n",
    "    },"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
